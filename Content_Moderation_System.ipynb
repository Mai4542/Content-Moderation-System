{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xl8ZLZbonFuy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/Mai4542/Content-Moderation-System/main/train.csv\"\n",
        "train = pd.read_csv(url,\n",
        "                   on_bad_lines='skip',\n",
        "                   engine='python')"
      ],
      "metadata": {
        "id": "4FKMJzKBWTWp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "z9Ta6vrgVm9F"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "eFni874FYrOm"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile(\"train.csv.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\"/content/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DbxGXWt6Yv8K"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# print(os.listdir(\"/content\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "cdXeuHKvYz4x"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# train = pd.read_csv(\"/content/train.csv\")\n",
        "# print(train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ikSfADFDxOz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd017492-c310-4231-84be-5d59e1393e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "english_stopwords = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "tk_uy0R2yMn0"
      },
      "outputs": [],
      "source": [
        "train.columns = train.columns.str.replace('\"', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "17WU8jl5nswi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0318c6-f209-422b-c007-04bb2bb748e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows:\n",
            "                 id                                       comment_text  toxic  \\\n",
            "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
            "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
            "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
            "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
            "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
            "\n",
            "   severe_toxic  obscene  threat  insult  identity_hate  \n",
            "0             0        0       0       0              0  \n",
            "1             0        0       0       0              0  \n",
            "2             0        0       0       0              0  \n",
            "3             0        0       0       0              0  \n",
            "4             0        0       0       0              0  \n"
          ]
        }
      ],
      "source": [
        "print(\"First few rows:\")\n",
        "print(train.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SikSNSAyoBUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f227378d-eea3-40cb-abef-8ecc15c5f791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset shape: (159571, 8)\n",
            "\n",
            "Columns: ['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDataset shape:\", train.shape)\n",
        "print(\"\\nColumns:\", train.columns.tolist())\n",
        "print(\"\\nDataset info:\")\n",
        "print(train.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "HlbouxxlpEfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6417284b-baf6-4bb4-f5e8-490e72326d96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values before processing:\n",
            "id               0\n",
            "comment_text     0\n",
            "toxic            0\n",
            "severe_toxic     0\n",
            "obscene          0\n",
            "threat           0\n",
            "insult           0\n",
            "identity_hate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values before processing:\")\n",
        "print(train.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "LM5tunr9pYa0"
      },
      "outputs": [],
      "source": [
        "train = train.dropna(subset=['comment_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "RbzJ_Mg7paZJ"
      },
      "outputs": [],
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train[label_cols] = train[label_cols].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "mbUWksOUqkB2"
      },
      "outputs": [],
      "source": [
        "train = train.drop_duplicates()\n",
        "train = train.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Yh9a247MzHU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdd51cc-0934-4955-bcd1-3fd896f14325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values after processing:\n",
            "id               0\n",
            "comment_text     0\n",
            "toxic            0\n",
            "severe_toxic     0\n",
            "obscene          0\n",
            "threat           0\n",
            "insult           0\n",
            "identity_hate    0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMissing values after processing:\")\n",
        "print(train.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uPGnigDuC1Z"
      },
      "source": [
        "# **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fTwm2m2GsSFQ"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    text = \" \".join([word for word in text.split() if word not in english_stopwords])\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "8dl0oqdisVqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd0a27e-9f91-45fd-ab04-63fd28f5e0c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text cleaning example:\n",
            "Before: D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
            "After: daww matches background colour im seemingly stuck thanks talk january utc\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nText cleaning example:\")\n",
        "print(\"Before:\", train['comment_text'].iloc[1])\n",
        "train['clean_comment'] = train['comment_text'].apply(clean_text)\n",
        "print(\"After:\", train['clean_comment'].iloc[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5quDC3RuWbh"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6S7GWCcZtE7p"
      },
      "outputs": [],
      "source": [
        "def extract_features(df):\n",
        "\n",
        "    df['char_count'] = df['clean_comment'].apply(len)\n",
        "    df['word_count'] = df['clean_comment'].apply(lambda x: len(x.split()))\n",
        "\n",
        "    df['caps_ratio'] = df['comment_text'].apply(\n",
        "        lambda x: sum(1 for c in str(x) if c.isupper()) / max(len(str(x)), 1)\n",
        "    )\n",
        "\n",
        "    df['url_count'] = df['comment_text'].apply(\n",
        "        lambda x: len(re.findall(r'http\\S+|www\\S+', str(x)))\n",
        "    )\n",
        "\n",
        "    df['mention_count'] = df['comment_text'].apply(lambda x: str(x).count('@'))\n",
        "\n",
        "    df['hashtag_count'] = df['comment_text'].apply(lambda x: str(x).count('#'))\n",
        "\n",
        "    df['repeated_chars'] = df['clean_comment'].apply(\n",
        "        lambda x: 1 if re.search(r'(.)\\1{2,}', x) else 0\n",
        "    )\n",
        "\n",
        "    df['avg_word_length'] = df['clean_comment'].apply(\n",
        "        lambda x: np.mean([len(word) for word in x.split()]) if len(x.split()) > 0 else 0\n",
        "    )\n",
        "\n",
        "    df['space_ratio'] = df['comment_text'].apply(\n",
        "        lambda x: str(x).count(' ') / max(len(str(x)), 1)\n",
        "    )\n",
        "\n",
        "    df['exclamation_count'] = df['comment_text'].apply(lambda x: str(x).count('!'))\n",
        "    df['question_count'] = df['comment_text'].apply(lambda x: str(x).count('?'))\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "W3ffEEa3uoq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f84730-609a-4f7b-d076-97fe939dd744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features extracted:\n",
            "                                       clean_comment  char_count  word_count  \\\n",
            "0  explanation edits made username hardcore metal...         173          26   \n",
            "1  daww matches background colour im seemingly st...          73          11   \n",
            "2  hey man im really trying edit war guy constant...         144          22   \n",
            "3  cant make real suggestions improvement wondere...         368          49   \n",
            "4                sir hero chance remember page thats          35           6   \n",
            "\n",
            "   caps_ratio  url_count  mention_count  hashtag_count  repeated_chars  \n",
            "0    0.064394          0              0              0               0  \n",
            "1    0.071429          0              0              0               0  \n",
            "2    0.017167          0              0              0               0  \n",
            "3    0.017685          0              0              1               0  \n",
            "4    0.029851          0              0              0               0  \n"
          ]
        }
      ],
      "source": [
        "train = extract_features(train)\n",
        "\n",
        "print(\"\\nFeatures extracted:\")\n",
        "print(train[['clean_comment', 'char_count', 'word_count', 'caps_ratio',\n",
        "             'url_count', 'mention_count', 'hashtag_count', 'repeated_chars']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "WCgIAaqk0P06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "777985e4-9614-434b-a43b-a3702e813e0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
              "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
              "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
              "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
              "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "0             0        0       0       0              0   \n",
              "1             0        0       0       0              0   \n",
              "2             0        0       0       0              0   \n",
              "3             0        0       0       0              0   \n",
              "4             0        0       0       0              0   \n",
              "5             0        0       0       0              0   \n",
              "6             1        1       0       1              0   \n",
              "7             0        0       0       0              0   \n",
              "8             0        0       0       0              0   \n",
              "9             0        0       0       0              0   \n",
              "\n",
              "                                       clean_comment  char_count  word_count  \\\n",
              "0  explanation edits made username hardcore metal...         173          26   \n",
              "1  daww matches background colour im seemingly st...          73          11   \n",
              "2  hey man im really trying edit war guy constant...         144          22   \n",
              "3  cant make real suggestions improvement wondere...         368          49   \n",
              "4                sir hero chance remember page thats          35           6   \n",
              "5         congratulations well use tools well · talk          42           7   \n",
              "6                        cocksucker piss around work          27           4   \n",
              "7  vandalism matt shirvington article reverted pl...          62           8   \n",
              "8  sorry word nonsense offensive anyway im intend...         284          39   \n",
              "9               alignment subject contrary dulithgow          36           4   \n",
              "\n",
              "   caps_ratio  url_count  mention_count  hashtag_count  repeated_chars  \\\n",
              "0    0.064394          0              0              0               0   \n",
              "1    0.071429          0              0              0               0   \n",
              "2    0.017167          0              0              0               0   \n",
              "3    0.017685          0              0              1               0   \n",
              "4    0.029851          0              0              0               0   \n",
              "5    0.015385          0              0              0               0   \n",
              "6    0.840909          0              0              0               0   \n",
              "7    0.034783          0              0              0               0   \n",
              "8    0.014831          0              0              0               0   \n",
              "9    0.028571          0              0              0               0   \n",
              "\n",
              "   avg_word_length  space_ratio  exclamation_count  question_count  \n",
              "0         5.692308     0.155303                  0               1  \n",
              "1         5.727273     0.151786                  1               0  \n",
              "2         5.590909     0.175966                  0               0  \n",
              "3         6.530612     0.178457                  0               0  \n",
              "4         5.000000     0.179104                  0               1  \n",
              "5         5.142857     0.169231                  0               0  \n",
              "6         6.000000     0.159091                  0               0  \n",
              "7         6.875000     0.173913                  0               0  \n",
              "8         6.307692     0.173729                  0               1  \n",
              "9         8.250000     0.157143                  0               0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fdb48c4-ebcf-48b7-b3e8-c288480d6874\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>clean_comment</th>\n",
              "      <th>char_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>caps_ratio</th>\n",
              "      <th>url_count</th>\n",
              "      <th>mention_count</th>\n",
              "      <th>hashtag_count</th>\n",
              "      <th>repeated_chars</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>space_ratio</th>\n",
              "      <th>exclamation_count</th>\n",
              "      <th>question_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation edits made username hardcore metal...</td>\n",
              "      <td>173</td>\n",
              "      <td>26</td>\n",
              "      <td>0.064394</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.692308</td>\n",
              "      <td>0.155303</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>daww matches background colour im seemingly st...</td>\n",
              "      <td>73</td>\n",
              "      <td>11</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.727273</td>\n",
              "      <td>0.151786</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man im really trying edit war guy constant...</td>\n",
              "      <td>144</td>\n",
              "      <td>22</td>\n",
              "      <td>0.017167</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.590909</td>\n",
              "      <td>0.175966</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>cant make real suggestions improvement wondere...</td>\n",
              "      <td>368</td>\n",
              "      <td>49</td>\n",
              "      <td>0.017685</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.530612</td>\n",
              "      <td>0.178457</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sir hero chance remember page thats</td>\n",
              "      <td>35</td>\n",
              "      <td>6</td>\n",
              "      <td>0.029851</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.179104</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>congratulations well use tools well · talk</td>\n",
              "      <td>42</td>\n",
              "      <td>7</td>\n",
              "      <td>0.015385</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.142857</td>\n",
              "      <td>0.169231</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>cocksucker piss around work</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>0.840909</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>vandalism matt shirvington article reverted pl...</td>\n",
              "      <td>62</td>\n",
              "      <td>8</td>\n",
              "      <td>0.034783</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.875000</td>\n",
              "      <td>0.173913</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sorry word nonsense offensive anyway im intend...</td>\n",
              "      <td>284</td>\n",
              "      <td>39</td>\n",
              "      <td>0.014831</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.307692</td>\n",
              "      <td>0.173729</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>alignment subject contrary dulithgow</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>0.028571</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.250000</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fdb48c4-ebcf-48b7-b3e8-c288480d6874')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fdb48c4-ebcf-48b7-b3e8-c288480d6874 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fdb48c4-ebcf-48b7-b3e8-c288480d6874');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-73b40e13-60e9-479e-9d52-eee9f055ad8b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73b40e13-60e9-479e-9d52-eee9f055ad8b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-73b40e13-60e9-479e-9d52-eee9f055ad8b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xcHHWiijZnJ"
      },
      "source": [
        "# **Rule-Based Filter**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BVvF9sP3jhNn"
      },
      "outputs": [],
      "source": [
        "# Rule-Based Filter System\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Keyword blacklists for offensive/banned terms\n",
        "OFFENSIVE_KEYWORDS = [\n",
        "    # Strong offensive terms\n",
        "    'fuck', 'shit', 'asshole', 'bastard', 'bitch', 'cunt', 'whore', 'dick', 'pussy',\n",
        "    'cock', 'motherfucker', 'crap', 'damn', 'hell', 'douche', 'slut', 'whore', 'prostitute',\n",
        "\n",
        "    # Insults and hate speech\n",
        "    'stupid', 'idiot', 'moron', 'retard', 'fool', 'dumb', 'retarded', 'imbecile',\n",
        "    'hate', 'kill', 'die', 'hurt', 'attack', 'harm', 'destroy', 'murder', 'suicide',\n",
        "    'loser', 'worthless', 'useless', 'trash', 'garbage', 'scum', 'jerk', 'scumbag',\n",
        "\n",
        "    # Racial/identity slurs\n",
        "    'nigger', 'nigga', 'chink', 'spic', 'kike', 'fag', 'faggot', 'dyke', 'tranny',\n",
        "    'terrorist', 'nazi', 'racist', 'supremacist', 'bigot', 'homophobe', 'transphobe',\n",
        "\n",
        "    # Sexual content\n",
        "    'pedophile', 'rapist', 'molest', 'rape', 'incest', 'porn', 'xxx', 'pedo', 'childporn',\n",
        "\n",
        "    # Add variations and common misspellings\n",
        "    'fuk', 'fck', 'fuc', 'f*ck', 'f**k', 'f***', 'f****', 'f**', 'f***',\n",
        "    'sh*t', 'sht', 'sh1t', 'sh!t', 's**t',\n",
        "    'b*tch', 'b**ch', 'b***h', 'biatch', 'bit*h',\n",
        "    'a$$', 'a55', 'a**', 'assh*le',\n",
        "    'd*ck', 'd**k', 'd***',\n",
        "    'p*ssy', 'p**sy', 'p***y',\n",
        "    'c*nt', 'c**t', 'c***',\n",
        "    'n*gger', 'n**ga', 'n***a',\n",
        "    'ret*rd', 'r*tard',\n",
        "    '5hit', '5hit', 'f00k', 'f00',\n",
        "\n",
        "    # Additional common variations\n",
        "    'fword', 'sword', 'thefword', 'thesword', 'fing', 'focking', 'focking'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9xQOYuPCj4-D"
      },
      "outputs": [],
      "source": [
        "SUSPICIOUS_PATTERNS = [\n",
        "    'buy now', 'purchase here', 'click here', 'discount', 'limited time',\n",
        "    'offer', 'promo code', 'cheap', 'deal', 'sale', 'order now',\n",
        "    'cheapest', 'lowest price', 'make money', 'earn fast', 'work from home',\n",
        "    'get rich', 'financial freedom',\n",
        "\n",
        "    # New spam phrases\n",
        "    'free followers', 'free prizes', 'free money', 'win free', 'sign up',\n",
        "    'download this app', 'visit this website', 'instantly', 'limited stock'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "RKpbi7PZj_VW"
      },
      "outputs": [],
      "source": [
        "# 3. Excessive patterns\n",
        "EXCESSIVE_PATTERNS = {\n",
        "    'caps': r'[A-Z]{4,}',  # 4 or more consecutive uppercase letters\n",
        "    'repetition': r'(\\w)\\1{3,}',  # 4 or more repeated characters\n",
        "    'exclamation': r'!{3,}',  # 3 or more exclamation marks\n",
        "    'question': r'\\?{3,}',  # 3 or more question marks\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_offensive_keywords_safe(text):\n",
        "    \"\"\"Enhanced detection that handles all variations\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return 0, []\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_keywords = []\n",
        "\n",
        "    # Check each offensive keyword\n",
        "    for keyword in OFFENSIVE_KEYWORDS:\n",
        "        # Simple containment check (works for most cases)\n",
        "        if keyword in text_lower:\n",
        "            found_keywords.append(keyword)\n",
        "            continue\n",
        "\n",
        "        # Check with word boundaries approximation\n",
        "        if f\" {keyword} \" in f\" {text_lower} \":\n",
        "            found_keywords.append(keyword)\n",
        "            continue\n",
        "\n",
        "        # Check for common separators\n",
        "        for sep in ['', ' ', '.', ',', '!', '?', '*', '-', '_']:\n",
        "            if f\"{sep}{keyword}{sep}\" in text_lower:\n",
        "                found_keywords.append(keyword)\n",
        "                break\n",
        "\n",
        "    return len(found_keywords), found_keywords"
      ],
      "metadata": {
        "id": "KWjpuQxf2rpV"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NSNA17dKkDwy"
      },
      "outputs": [],
      "source": [
        "def detect_suspicious_patterns_safe(text):\n",
        "    \"\"\"Detect suspicious promotional patterns without regex\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return 0, []\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    found_patterns = []\n",
        "\n",
        "    for pattern in SUSPICIOUS_PATTERNS:\n",
        "        if pattern in text_lower:\n",
        "            found_patterns.append(pattern)\n",
        "\n",
        "    return len(found_patterns), found_patterns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_excessive_patterns_safe(text):\n",
        "    \"\"\"Detect excessive patterns without any regex\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return {}\n",
        "\n",
        "    results = {\n",
        "        'excessive_caps': 0,\n",
        "        'character_repetition': 0,\n",
        "        'excessive_exclamation': 0,\n",
        "        'excessive_question': 0\n",
        "    }\n",
        "\n",
        "    # Check for excessive caps (4+ consecutive uppercase)\n",
        "    consecutive_caps = 0\n",
        "    for char in text:\n",
        "        if char.isupper():\n",
        "            consecutive_caps += 1\n",
        "            if consecutive_caps >= 4:\n",
        "                results['excessive_caps'] += 1\n",
        "        else:\n",
        "            consecutive_caps = 0\n",
        "\n",
        "    # Check for character repetition (4+ same character in a row)\n",
        "    for i in range(len(text) - 3):\n",
        "        if text[i] == text[i+1] == text[i+2] == text[i+3] and text[i].isalnum():\n",
        "            results['character_repetition'] += 1\n",
        "\n",
        "    # Check for excessive punctuation\n",
        "    consecutive_excl = 0\n",
        "    for char in text:\n",
        "        if char == '!':\n",
        "            consecutive_excl += 1\n",
        "            if consecutive_excl >= 3:\n",
        "                results['excessive_exclamation'] += 1\n",
        "        else:\n",
        "            consecutive_excl = 0\n",
        "\n",
        "    consecutive_quest = 0\n",
        "    for char in text:\n",
        "        if char == '?':\n",
        "            consecutive_quest += 1\n",
        "            if consecutive_quest >= 3:\n",
        "                results['excessive_question'] += 1\n",
        "        else:\n",
        "            consecutive_quest = 0\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "Z4jjPHm-17Pl"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_risk_score(keyword_count, pattern_count, excessive_results):\n",
        "    \"\"\"Calculate overall risk score based on all factors\"\"\"\n",
        "    # Weighted scoring\n",
        "    score = (\n",
        "        min(keyword_count * 0.3, 1.0) +  # Max 1.0 for keywords\n",
        "        min(pattern_count * 0.2, 0.5) +   # Max 0.5 for patterns\n",
        "        min(excessive_results.get('excessive_caps', 0) * 0.1, 0.2) +\n",
        "        min(excessive_results.get('character_repetition', 0) * 0.1, 0.2) +\n",
        "        min(excessive_results.get('excessive_exclamation', 0) * 0.05, 0.05) +\n",
        "        min(excessive_results.get('excessive_question', 0) * 0.05, 0.05)\n",
        "    )\n",
        "\n",
        "    return min(score, 1.0)  # Cap at 1.0"
      ],
      "metadata": {
        "id": "c8m6DWhu2IWr"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "U1PfhDIHkNca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f41b176-ebe4-417d-eda7-38340f52539e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying completely regex-free rule-based filter to comments...\n",
            "Filter applied successfully!\n",
            "\n",
            "Rule-based filter results:\n",
            "                                        comment_text  risk_score risk_level  \\\n",
            "0  Explanation\\nWhy the edits made under my usern...         0.0        low   \n",
            "1  D'aww! He matches this background colour I'm s...         0.0        low   \n",
            "2  Hey man, I'm really not trying to edit war. It...         0.0        low   \n",
            "3  \"\\nMore\\nI can't make any real suggestions on ...         0.0        low   \n",
            "4  You, sir, are my hero. Any chance you remember...         0.0        low   \n",
            "5  \"\\n\\nCongratulations from me as well, use the ...         0.0        low   \n",
            "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK         0.5     medium   \n",
            "7  Your vandalism to the Matt Shirvington article...         0.0        low   \n",
            "8  Sorry if the word 'nonsense' was offensive to ...         0.0        low   \n",
            "9  alignment on this subject and which are contra...         0.0        low   \n",
            "\n",
            "        action  offensive_keywords_count  suspicious_patterns_count  \n",
            "0         safe                         0                          0  \n",
            "1         safe                         0                          0  \n",
            "2         safe                         0                          0  \n",
            "3         safe                         0                          0  \n",
            "4         safe                         0                          0  \n",
            "5         safe                         0                          0  \n",
            "6  medium_risk                         1                          0  \n",
            "7         safe                         0                          0  \n",
            "8         safe                         0                          0  \n",
            "9         safe                         0                          0  \n"
          ]
        }
      ],
      "source": [
        "def rule_based_filter_safe(text):\n",
        "    \"\"\"Main rule-based filter function - COMPLETELY REGEX-FREE\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return {\n",
        "            'offensive_keywords_count': 0,\n",
        "            'offensive_keywords_found': [],\n",
        "            'suspicious_patterns_count': 0,\n",
        "            'suspicious_patterns_found': [],\n",
        "            'excessive_patterns': {},\n",
        "            'risk_score': 0,\n",
        "            'risk_level': 'low',\n",
        "            'action': 'safe'\n",
        "        }\n",
        "\n",
        "    # Detect offensive keywords\n",
        "    keyword_count, found_keywords = detect_offensive_keywords_safe(text)\n",
        "\n",
        "    # Detect suspicious patterns\n",
        "    pattern_count, found_patterns = detect_suspicious_patterns_safe(text)\n",
        "\n",
        "    # Detect excessive patterns using safe method\n",
        "    excessive_results = detect_excessive_patterns_safe(text)\n",
        "\n",
        "    # Calculate risk score\n",
        "    risk_score = calculate_risk_score(keyword_count, pattern_count, excessive_results)\n",
        "\n",
        "    # Determine action\n",
        "    if pattern_count > 0:\n",
        "        action = 'spam'\n",
        "    elif risk_score >= 0.7:\n",
        "        action = 'high_risk'\n",
        "    elif risk_score >= 0.4:\n",
        "        action = 'medium_risk'\n",
        "    else:\n",
        "        action = 'safe'\n",
        "\n",
        "    # Map action to risk_level for backward compatibility\n",
        "    if action == 'high_risk':\n",
        "        risk_level = 'high'\n",
        "    elif action == 'medium_risk':\n",
        "        risk_level = 'medium'\n",
        "    else:\n",
        "        risk_level = 'low'\n",
        "\n",
        "    return {\n",
        "        'offensive_keywords_count': keyword_count,\n",
        "        'offensive_keywords_found': found_keywords,\n",
        "        'suspicious_patterns_count': pattern_count,\n",
        "        'suspicious_patterns_found': found_patterns,\n",
        "        'excessive_patterns': excessive_results,\n",
        "        'risk_score': risk_score,\n",
        "        'risk_level': risk_level,\n",
        "        'action': action\n",
        "    }\n",
        "\n",
        "# Apply the filter\n",
        "print(\"Applying completely regex-free rule-based filter to comments...\")\n",
        "\n",
        "sample_size = min(1000, len(train))\n",
        "train_sample = train.head(sample_size).copy()\n",
        "\n",
        "filter_results = train_sample['comment_text'].apply(rule_based_filter_safe)\n",
        "print(\"Filter applied successfully!\")\n",
        "\n",
        "# Convert results to DataFrame and merge with original data\n",
        "filter_results_df = pd.DataFrame(filter_results.tolist())\n",
        "train_with_filter = pd.concat([train_sample, filter_results_df], axis=1)\n",
        "\n",
        "print(\"\\nRule-based filter results:\")\n",
        "print(train_with_filter[['comment_text', 'risk_score', 'risk_level', 'action',\n",
        "                         'offensive_keywords_count', 'suspicious_patterns_count']].head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2ZB_1o2QlRKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70b59c8-9afd-452f-8382-12a6bb02a319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rule-based filter results:\n",
            "                                        comment_text  risk_score risk_level  \\\n",
            "0  Explanation\\nWhy the edits made under my usern...         0.0        low   \n",
            "1  D'aww! He matches this background colour I'm s...         0.0        low   \n",
            "2  Hey man, I'm really not trying to edit war. It...         0.0        low   \n",
            "3  \"\\nMore\\nI can't make any real suggestions on ...         0.0        low   \n",
            "4  You, sir, are my hero. Any chance you remember...         0.0        low   \n",
            "5  \"\\n\\nCongratulations from me as well, use the ...         0.0        low   \n",
            "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK         0.5     medium   \n",
            "7  Your vandalism to the Matt Shirvington article...         0.0        low   \n",
            "8  Sorry if the word 'nonsense' was offensive to ...         0.0        low   \n",
            "9  alignment on this subject and which are contra...         0.0        low   \n",
            "\n",
            "   offensive_keywords_count  suspicious_patterns_count  \n",
            "0                         0                          0  \n",
            "1                         0                          0  \n",
            "2                         0                          0  \n",
            "3                         0                          0  \n",
            "4                         0                          0  \n",
            "5                         0                          0  \n",
            "6                         1                          0  \n",
            "7                         0                          0  \n",
            "8                         0                          0  \n",
            "9                         0                          0  \n",
            "\n",
            "Risk Level Distribution:\n",
            "risk_level\n",
            "low       895\n",
            "medium     58\n",
            "high       47\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Average risk score by toxicity label:\n",
            "toxic\n",
            "0    0.092402\n",
            "1    0.527143\n",
            "Name: risk_score, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Display results\n",
        "print(\"\\nRule-based filter results:\")\n",
        "print(train_with_filter[['comment_text', 'risk_score', 'risk_level',\n",
        "                         'offensive_keywords_count', 'suspicious_patterns_count']].head(10))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nRisk Level Distribution:\")\n",
        "print(train_with_filter['risk_level'].value_counts())\n",
        "\n",
        "print(\"\\nAverage risk score by toxicity label:\")\n",
        "if 'toxic' in train_with_filter.columns:\n",
        "    print(train_with_filter.groupby('toxic')['risk_score'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "MmLL69DtmbOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adca6408-4bd4-4262-9dc0-02a5a4f2bc15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data with rule-based filter saved to: /content/sample_data/train_with_rule_filter.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the results with rule-based filtering\n",
        "output_path = \"/content/sample_data/train_with_rule_filter.csv\"\n",
        "train_with_filter.to_csv(output_path, index=False)\n",
        "print(f\"\\nData with rule-based filter saved to: {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha5T9ooliR9U"
      },
      "source": [
        "# **Machine Learning** **Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "RLfCiREhbX5R"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack,csr_matrix\n",
        "x_text=train['clean_comment']\n",
        "x_features=train[['char_count', 'word_count', 'caps_ratio',\n",
        "             'url_count', 'mention_count', 'hashtag_count', 'repeated_chars','avg_word_length','space_ratio','exclamation_count','question_count']]\n",
        "x_features=csr_matrix(x_features.values)\n",
        "vectorizer = TfidfVectorizer(max_features=5000, stop_words=\"english\")\n",
        "X_text_tfidf = vectorizer.fit_transform(x_text)\n",
        "X = hstack([X_text_tfidf, x_features])\n",
        "y=train[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
        "             'insult', 'identity_hate']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "jF2Qus5JhbZL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "nR0KuVy7kAhj"
      },
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.multiclass import OneVsRestClassifier\n",
        "# from sklearn.metrics import classification_report\n",
        "# model = OneVsRestClassifier(LogisticRegression(max_iter=3000))\n",
        "# model.fit(x_train, y_train)\n",
        "# y_pred = model.predict(x_test)\n",
        "# print(classification_report(y_test, y_pred, target_names=y.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "FSes2kb2lhD8"
      },
      "outputs": [],
      "source": [
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# from sklearn.multiclass import OneVsRestClassifier\n",
        "# model_nb = OneVsRestClassifier(MultinomialNB())\n",
        "# model_nb.fit(x_train, y_train)\n",
        "# y_pred_nb = model_nb.predict(x_test)\n",
        "# print(classification_report(y_test, y_pred_nb, target_names=y.columns))\n",
        "# # NOOOOOOOO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "-lrv_FWTmZLD"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.multiclass import OneVsRestClassifier\n",
        "# from sklearn.metrics import classification_report\n",
        "# model_rf = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "# model_rf.fit(x_train, y_train)\n",
        "# y_pred_rf = model_rf.predict(x_test)\n",
        "# print(classification_report(y_test, y_pred_rf, target_names=y.columns))\n",
        "# #NOOOOOOO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "m4UC7mghmx3F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01961c91-ce7d-48db-d5e2-e12ae852a1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        toxic       0.57      0.83      0.67      3056\n",
            " severe_toxic       0.24      0.79      0.37       321\n",
            "      obscene       0.56      0.86      0.68      1715\n",
            "       threat       0.14      0.64      0.23        74\n",
            "       insult       0.44      0.84      0.58      1614\n",
            "identity_hate       0.17      0.66      0.27       294\n",
            "\n",
            "    micro avg       0.46      0.83      0.59      7074\n",
            "    macro avg       0.35      0.77      0.47      7074\n",
            " weighted avg       0.50      0.83      0.62      7074\n",
            "  samples avg       0.06      0.08      0.06      7074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report,accuracy_score\n",
        "model_svm = OneVsRestClassifier(LinearSVC(class_weight=\"balanced\", max_iter=5000))\n",
        "model_svm.fit(x_train, y_train)\n",
        "y_pred_svm = model_svm.predict(x_test)\n",
        "print(classification_report(y_test, y_pred_svm, target_names=y.columns))\n",
        "#THE RIGHT MODEL\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CTVw4Lc-EzBw"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n",
        "def prepare_row_for_model(row, vectorizer):\n",
        "    text = row['clean_comment']\n",
        "    X_text = vectorizer.transform([text])\n",
        "    num_features = ['char_count', 'word_count', 'caps_ratio',\n",
        "                    'url_count', 'mention_count', 'hashtag_count',\n",
        "                    'repeated_chars', 'avg_word_length',\n",
        "                    'space_ratio', 'exclamation_count', 'question_count']\n",
        "    x_features = row[num_features].astype(float).values.reshape(1, -1)\n",
        "    x_features = csr_matrix(x_features)\n",
        "    return hstack([X_text, x_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "xZrNdvSWE8hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3903b00-e504-4fad-8fd0-5db10a1b4d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "row = train.iloc[6]\n",
        "X_row = prepare_row_for_model(row, vectorizer)\n",
        "pred = model_svm.predict(X_row)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "zM8OAXmkGu00"
      },
      "outputs": [],
      "source": [
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "def interpret_prediction(pred):\n",
        "    pred = pred[0]\n",
        "    toxic_related = {\"toxic\", \"severe_toxic\", \"obscene\", \"insult\", \"identity_hate\"}\n",
        "    spam_related = {\"threat\"}\n",
        "    # multi-labels detected\n",
        "    active_labels = [labels[i] for i, val in enumerate(pred) if val == 1]\n",
        "    if active_labels:\n",
        "        print(\"Detected labels:\", \", \".join(active_labels))\n",
        "    else:\n",
        "        print(\"Detected labels: None\")\n",
        "    # final result\n",
        "    if any(label in spam_related for label in active_labels):\n",
        "        print(\"Final Result: spam\")\n",
        "    elif any(label in toxic_related for label in active_labels):\n",
        "        print(\"Final Result: toxic\")\n",
        "    else:\n",
        "        print(\"Final Result: safe\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "u_m33m-rQisl"
      },
      "outputs": [],
      "source": [
        "def extract_features_single(comment, clean_comment):\n",
        "    return [\n",
        "        len(clean_comment),                             # char_count\n",
        "        len(clean_comment.split()),                     # word_count\n",
        "        sum(1 for c in comment if c.isupper()) / max(len(comment), 1),  # caps_ratio\n",
        "        len(re.findall(r'http\\S+|www\\S+', comment)),    # url_count\n",
        "        comment.count('@'),                             # mention_count\n",
        "        comment.count('#'),                             # hashtag_count\n",
        "        1 if re.search(r'(.)\\1{2,}', clean_comment) else 0,  # repeated_chars\n",
        "        np.mean([len(w) for w in clean_comment.split()]) if clean_comment.split() else 0,  # avg_word_length\n",
        "        comment.count(' ') / max(len(comment), 1),      # space_ratio\n",
        "        comment.count('!'),                             # exclamation_count\n",
        "        comment.count('?')                              # question_count\n",
        "    ]\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "\n",
        "def prepare_single_comment(comment, vectorizer):\n",
        "    clean_comment = clean_text(comment)\n",
        "    comment_tfidf = vectorizer.transform([clean_comment])\n",
        "    features = extract_features_single(comment, clean_comment)\n",
        "    features_sparse = csr_matrix([features])  # 2D\n",
        "    final_input = hstack([comment_tfidf, features_sparse])\n",
        "    return final_input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "M9YE59mjSkHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1e96364-faef-412a-c2f2-57d74e7f2e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1 1 0 1 0]]\n",
            "Detected labels: toxic, severe_toxic, obscene, insult\n",
            "Final Result: toxic\n"
          ]
        }
      ],
      "source": [
        "pre_comment=\"COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\"\n",
        "comment=prepare_single_comment(pre_comment,vectorizer)\n",
        "pred = model_svm.predict(comment)\n",
        "print(pred)\n",
        "interpret_prediction(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "LH2wwa6HUjtH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30dd4ffa-fb6b-4162-8768-eae7a9b9dc27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8360645464515118"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "acc = accuracy_score(y_test, y_pred_svm)\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "jo8CmfK_FlU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fb886d-3e8e-433d-f84d-54524c0cae56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(model_svm, \"content_moderation_model.pkl\")\n",
        "joblib.dump(vectorizer, \"vectorizer.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RiskAssessmentEngine"
      ],
      "metadata": {
        "id": "8GzIePxUGW_A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "sgwyV6HCPSey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89bd4d6d-ce54-4051-f9f5-69bbd20ec09d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.44.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.12.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.12.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.11)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.12.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Testing fixed engine:\n",
            "Text: 'buy now and get free prizes' -> spam (rule: 0.4, ml: 0.8, combined: 0.68)\n",
            "Text: 'I will kill you' -> toxic (rule: 0.3, ml: 0.8, combined: 0.65)\n",
            "Text: 'This is a normal comment' -> toxic (rule: 0.0, ml: 0.8, combined: 0.56)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/interface.py:414: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated. Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://12c6762449cb5745a0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://12c6762449cb5745a0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "# RiskAssessmentEngine - MODIFIED FOR SPAM DETECTION\n",
        "!pip install gradio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "\n",
        "def extract_features_single_fixed(comment):\n",
        "    clean_comment = clean_text(comment)\n",
        "    return [\n",
        "        len(clean_comment),\n",
        "        len(clean_comment.split()),\n",
        "        sum(1 for c in comment if c.isupper()) / max(len(comment), 1),\n",
        "        comment.count('http'),\n",
        "        comment.count('@'),\n",
        "        comment.count('#'),\n",
        "        0,\n",
        "        np.mean([len(w) for w in clean_comment.split()]) if clean_comment.split() else 0,\n",
        "        comment.count(' ') / max(len(comment), 1),\n",
        "        comment.count('!'),\n",
        "        comment.count('?')\n",
        "    ]\n",
        "\n",
        "def prepare_single_comment_fixed(comment, vectorizer):\n",
        "    clean_comment_text = clean_text(comment)\n",
        "    comment_tfidf = vectorizer.transform([clean_comment_text])\n",
        "    features = extract_features_single_fixed(comment)\n",
        "    features_sparse = csr_matrix([features])\n",
        "    return hstack([comment_tfidf, features_sparse])\n",
        "\n",
        "class RiskAssessmentEngine:\n",
        "    def __init__(self, model, vectorizer, filter_func, weights=None, thresholds=None):\n",
        "        self.model = model\n",
        "        self.vectorizer = vectorizer\n",
        "        self.filter_func = filter_func\n",
        "        self.weights = weights or {\"rule\": 0.7, \"ml\": 0.3}\n",
        "        self.thresholds = thresholds or {\"block\": 0.6, \"review\": 0.4}\n",
        "\n",
        "    def score_text(self, text, for_user=False):\n",
        "        # 1. Rule-based filter\n",
        "        rule_result = self.filter_func(text)\n",
        "        rule_score = rule_result.get(\"risk_score\", 0)\n",
        "        suspicious_patterns_count = rule_result.get(\"suspicious_patterns_count\", 0)\n",
        "\n",
        "        # 2. ML model prediction\n",
        "        try:\n",
        "            X = prepare_single_comment_fixed(text, self.vectorizer)\n",
        "            ml_prediction = self.model.predict(X)[0]\n",
        "            ml_score = 0.8 if any(ml_prediction) else 0.1\n",
        "        except Exception as e:\n",
        "            print(f\"ML prediction error: {e}\")\n",
        "            ml_score = 0.1\n",
        "            ml_prediction = [0] * 6\n",
        "\n",
        "        # 3. Weighted combination\n",
        "        combined = 0.7 * rule_score + 0.3 * ml_score if not any(ml_prediction) else 0.3 * rule_score + 0.7 * ml_score\n",
        "\n",
        "        # 4. Action decision\n",
        "        threat_keywords = [\"destroy\", \"kill\", \"die\", \"attack\", \"hurt\", \"murder\"]\n",
        "        has_threat = any(keyword in text.lower() for keyword in threat_keywords)\n",
        "\n",
        "        if suspicious_patterns_count > 0:\n",
        "            action = \"spam\"\n",
        "        elif has_threat or any(ml_prediction):\n",
        "            action = \"toxic\"\n",
        "        elif rule_score >= self.thresholds[\"block\"] or combined >= self.thresholds[\"block\"]:\n",
        "            action = \"toxic\"\n",
        "        elif combined >= self.thresholds[\"review\"]:\n",
        "            action = \"toxic\"\n",
        "        else:\n",
        "            action = \"safe\"\n",
        "\n",
        "        if for_user:\n",
        "            return action\n",
        "        else:\n",
        "            return {\n",
        "                \"text\": text,\n",
        "                \"rule_score\": round(rule_score, 3),\n",
        "                \"ml_score\": round(ml_score, 3),\n",
        "                \"combined_score\": round(combined, 3),\n",
        "                \"action\": action,\n",
        "                \"ml_prediction\": ml_prediction.tolist() if hasattr(ml_prediction, 'tolist') else ml_prediction\n",
        "            }\n",
        "\n",
        "# Create fixed engine\n",
        "engine = RiskAssessmentEngine(\n",
        "    model=model_svm,\n",
        "    vectorizer=vectorizer,\n",
        "    filter_func=rule_based_filter_safe\n",
        ")\n",
        "\n",
        "# Test examples\n",
        "test_texts = [\n",
        "    \"buy now and get free prizes\",\n",
        "    \"I will kill you\",\n",
        "    \"This is a normal comment\"\n",
        "]\n",
        "\n",
        "print(\"Testing fixed engine:\")\n",
        "for text in test_texts:\n",
        "    result = engine.score_text(text)\n",
        "    print(f\"Text: '{text}' -> {result['action']} (rule: {result['rule_score']}, ml: {result['ml_score']}, combined: {result['combined_score']})\")\n",
        "\n",
        "# Gradio interface\n",
        "def predict_comment(comment):\n",
        "    return engine.score_text(comment, for_user=True)\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_comment,\n",
        "    inputs=gr.Textbox(lines=3, placeholder=\"Enter a comment...\"),\n",
        "    outputs=\"text\",\n",
        "    title=\"Content Moderation Checker\",\n",
        "    description=\"Classify comments into toxic, spam, or safe.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}